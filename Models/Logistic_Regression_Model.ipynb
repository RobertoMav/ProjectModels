{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "266f73ec",
   "metadata": {},
   "source": [
    "## Testing importing TF(Keras) logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348cfc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec6c61fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b604d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_pred(yhat):\n",
    "    if yhat >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74244782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_err(y, yhat):\n",
    "    m = y.shape[0]\n",
    "    incorrect = 0\n",
    "    y = y.tolist()\n",
    "    for i in range(m):\n",
    "        if yhat[i] != y[i]:\n",
    "            incorrect += 1\n",
    "            \n",
    "    incorrect = incorrect / m\n",
    "    \n",
    "    return incorrect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1456bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_output(prediction):\n",
    "    ex = prediction.shape[0]\n",
    "    output = []\n",
    "    for i in range(ex):\n",
    "        output.append(NN_pred(prediction[i]))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48d28ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>AgeFare</th>\n",
       "      <th>SibPar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>159.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2708.7654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>206.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1858.5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>281.7500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Q  S    AgeFare  SibPar\n",
       "0         0       3    1  22.0      1      0   7.2500  0  1   159.5000       1\n",
       "1         1       1    0  38.0      1      0  71.2833  0  0  2708.7654       1\n",
       "2         1       3    0  26.0      0      0   7.9250  0  1   206.0500       0\n",
       "3         1       1    0  35.0      1      0  53.1000  0  1  1858.5000       1\n",
       "4         0       3    1  35.0      0      0   8.0500  0  1   281.7500       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv((\"../TrainTestSet/TrainSet1.csv\"))\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b1781",
   "metadata": {},
   "source": [
    "### Creating x_train, y_train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1ec5c8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_set['Survived']\n",
    "x = train_set.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e42fc025",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36cf85a",
   "metadata": {},
   "source": [
    "### Fitting Sklearn logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "64bc3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sk_log = LogisticRegression(max_iter=1000, C=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d4cb080b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sk_log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c685bd13",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "648f3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_sk_log.predict(X_test)\n",
    "pred_train = model_sk_log.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5c2df",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f9e98443",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 80.731364\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: %f'%(np.mean(pred_train == y_train) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9997aa0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error test:  0.174\n",
      "error train: 0.193\n"
     ]
    }
   ],
   "source": [
    "error_cv = eval_err(y_test, pred_test)\n",
    "error_train = eval_err(y_train, pred_train)\n",
    "print(f\"error test:  {error_cv :0.3f}\")\n",
    "print(f\"error train: {error_train :0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b016ee50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       107\n",
      "           1       0.88      0.65      0.75        71\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.84      0.80      0.81       178\n",
      "weighted avg       0.83      0.83      0.82       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6566e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   6]\n",
      " [ 25  46]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618af669",
   "metadata": {},
   "source": [
    "# Building Log Reg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "af203c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de0225",
   "metadata": {},
   "source": [
    "### Scaling the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "efd565bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train, y_train)\n",
    "X_test = scaler.fit_transform(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00bf3d",
   "metadata": {},
   "source": [
    "## To create a Logistic Regression :\n",
    "##### 1. Create sigmoid function\n",
    "##### 2. Compute loss function, sum to get cost (add regularization)\n",
    "##### 3. Add gradient descent calculation \n",
    "##### 4. Updating the weights\n",
    "##### 5. Check predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499c74e",
   "metadata": {},
   "source": [
    "### 1. Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "52f4dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    calc = math.e**-z\n",
    "    g = 1 / (1 + calc)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00da34",
   "metadata": {},
   "source": [
    "#### Cost Function Reference (used Andrew Ng ML Specialization):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7778a",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 Cost function for logistic regression\n",
    "\n",
    "In this section, you will implement the cost function for logistic regression.\n",
    "\n",
    "<a name='ex-02'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Please complete the `compute_cost` function using the equations below.\n",
    "\n",
    "Recall that for logistic regression, the cost function is of the form \n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "where\n",
    "* m is the number of training examples in the dataset\n",
    "\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ is the cost for a single data point, which is - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ is the model's prediction, while $y^{(i)}$, which is the actual label\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ where function $g$ is the sigmoid function.\n",
    "    * It might be helpful to first calculate an intermediate variable $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ where $n$ is the number of features, before calculating $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102fe0ba",
   "metadata": {},
   "source": [
    "### 2. Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "036bcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(X, y, w, b, lambda_):\n",
    "    \n",
    "    train_ex, featur = X.shape\n",
    "    total_cost = 0 \n",
    "    \n",
    "    for i in range(train_ex):\n",
    "        \n",
    "        #Uses the activation function (sigmoid) \n",
    "        sig_i = sigmoid(np.dot(X[i],w) + b)\n",
    "        #Uses the loss function calculation\n",
    "        check = (- y[i] * np.log(sig_i)) - ((1 - y[i]) * np.log(1 - sig_i))\n",
    "        total_cost += check\n",
    "    \n",
    "    #Avgs to train_examples\n",
    "    total_cost = total_cost / train_ex\n",
    "    \n",
    "    #Regularization term \n",
    "    reg = 0\n",
    "    \n",
    "    for j in range(featur):\n",
    "        #Squares the weights\n",
    "        reg += w[j]**2\n",
    "    \n",
    "    #Uses the lambda to \"punish\" large weights\n",
    "    reg = lambda_/(2*featur * reg)\n",
    "    \n",
    "    #Cost function with the regularization added \n",
    "    final_cost = total_cost + reg\n",
    "    \n",
    "    return final_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f02264",
   "metadata": {},
   "source": [
    "### 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "419145b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w, b, lambda_):\n",
    "    train_ex, featur = X.shape\n",
    "    \n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "    \n",
    "    for i in range(train_ex):\n",
    "        pred = sigmoid(np.dot(X[i], w) + b)\n",
    "        #For each train example: takes the predction - the truth\n",
    "        dj_db += pred - y[i]\n",
    "        \n",
    "        for j in range(featur):\n",
    "            #For each train example and each feature within it: predction - the truth * value of [example] [feature]\n",
    "            dj_dw[j] += (pred - y[i]) * X[i][j]\n",
    "    \n",
    "    #Divides the w and b's derivatives per the number of features\n",
    "    dj_db = dj_db / featur\n",
    "    dj_dw = dj_dw / featur\n",
    "    \n",
    "    #Adds a regularization term to W's derivative (punish large weights)\n",
    "    for i in range(featur):\n",
    "        reg = lambda_ / featur * w[j]\n",
    "        dj_dw[j] += reg\n",
    "    \n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc2b72",
   "metadata": {},
   "source": [
    "### 4. Updates the weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f4d65c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w_in, b_in, cost_func, gradient_func, alpha, iterat, lambda_):\n",
    "    examples = X.shape[0]\n",
    "    #List to ilustrate the cost function history\n",
    "    Cost_Journey = []\n",
    "    \n",
    "    for i in range(iterat):\n",
    "        #For each iteration: call the gradient function and updates the weights and biases (mind the alpha hehe)\n",
    "        dj_dw, dj_db = gradient_func(X, y, w_in, b_in, lambda_)\n",
    "        \n",
    "        w_in = w_in - alpha * dj_dw\n",
    "        b_in = b_in - alpha * dj_db\n",
    "        \n",
    "        #Just a code to print the cost throughout the training\n",
    "        if i % (iterat/10) == 0 or i == (iterat-1):\n",
    "            cost = cost_func(X, y, w_in, b_in, lambda_)\n",
    "            Cost_Journey.append(cost)\n",
    "            print(f\"Iteration {i:4}: Cost {float(Cost_Journey[-1]):8.3f}   \")\n",
    "    \n",
    "    return w_in, b_in, Cost_Journey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50115e6e",
   "metadata": {},
   "source": [
    "### Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8a07b079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost    0.854   \n",
      "Iteration  500: Cost    0.446   \n",
      "Iteration 1000: Cost    0.446   \n",
      "Iteration 1500: Cost    0.446   \n",
      "Iteration 2000: Cost    0.446   \n",
      "Iteration 2500: Cost    0.446   \n",
      "Iteration 3000: Cost    0.446   \n",
      "Iteration 3500: Cost    0.446   \n",
      "Iteration 4000: Cost    0.446   \n",
      "Iteration 4500: Cost    0.446   \n",
      "Iteration 4999: Cost    0.446   \n"
     ]
    }
   ],
   "source": [
    "#Model parameters\n",
    "alpha = 0.01\n",
    "iterations = 5000      #After about 1K iter the cost function does not drop\n",
    "lambda_ = 0.001\n",
    "\n",
    "#Creates a random matrix for W to start diff from 0\n",
    "np.random.seed(1)\n",
    "i_w = np.random.rand(X_train.shape[1])-0.5\n",
    "i_b = 1.\n",
    "        \n",
    "w, b, cost = compute_gradient(X_train, y_train, i_w, i_b, loss_calc, gradient_descent, alpha, iterations, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "15779cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4470502037403722, 0.001, 0.001, 0.4472136616977054, 0.001, 0.01, 0.44884902254131775, 0.001, 0.1, 0.44647776173080006, 0.01, 0.001, 0.4466166457081425, 0.01, 0.01, 0.44800884883207254, 0.01, 0.1, 0.5188852241600901, 0.1, 0.001, 0.5189938257380772, 0.1, 0.01, 0.5200503059960984, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "#Something like a GridSearchCV \n",
    "#needs to create a list for alpha and lambda_\n",
    "answers = []\n",
    "for i in range(len(alpha)):\n",
    "    for j in range(len(lambda_)):\n",
    "        w, b, cost = compute_gradient(X_train, y_train, i_w, i_b, loss_calc, gradient_descent, alpha[i], iterations, lambda_[j])\n",
    "        answers.append(cost[-1])\n",
    "        answers.append(alpha[i])\n",
    "        answers.append(lambda_[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c1b37",
   "metadata": {},
   "source": [
    "### Function to get the prediction given a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5c5ab741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b, threshold):\n",
    "    m,n = X.shape\n",
    "    p = np.zeros(m)\n",
    "    \n",
    "    for i in range(m):\n",
    "        #Takes the predction given the weights and biases after adjustment\n",
    "        kick = np.dot(X[i], w) + b\n",
    "        \n",
    "        #Prediction threshold\n",
    "        if kick >= threshold:\n",
    "            p[i] = 1\n",
    "        else:\n",
    "            p[i] = 0\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ac3467",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6f20baf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 81.012658\n",
      "Test Accuracy: 81.460674\n"
     ]
    }
   ],
   "source": [
    "p_train = predict(X_train, w, b, 0.5)\n",
    "print('Train Accuracy: %f'%(np.mean(p_train == y_train) * 100))\n",
    "p = predict(X_test, w,b, 0.5)\n",
    "print('Test Accuracy: %f'%(np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ff287cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error cv:    0.185\n",
      "error train: 0.190\n"
     ]
    }
   ],
   "source": [
    "error_cv = eval_err(y_test, p)\n",
    "error_train = eval_err(y_train, p_train)\n",
    "print(f\"error cv:    {error_cv :0.3f}\")\n",
    "print(f\"error train: {error_train :0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b44584",
   "metadata": {},
   "source": [
    "## Result of Self-Made logistic Reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "be50e572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       107\n",
      "           1       0.91      0.59      0.72        71\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.85      0.78      0.79       178\n",
      "weighted avg       0.83      0.81      0.80       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ff570550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [ 29  42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
